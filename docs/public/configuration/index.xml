<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Configuration-rsses on Choria Orchestrator</title>
    <link>http://docs.choria.io/configuration/index.xml</link>
    <description>Recent content in Configuration-rsses on Choria Orchestrator</description>
    <generator>Hugo -- gohugo.io</generator>
    <atom:link href="http://docs.choria.io/configuration/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Optional Configuration</title>
      <link>http://docs.choria.io/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/</guid>
      <description>

&lt;h1 id=&#34;optional-configuration&#34;&gt;Optional Configuration&lt;/h1&gt;

&lt;p&gt;Past the initial &lt;a href=&#34;../deployment&#34;&gt;Deployment&lt;/a&gt; there are a few extra, but optional, things you can configure using Choria which this section covers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PuppetDB Discovery</title>
      <link>http://docs.choria.io/configuration/puppetdb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/puppetdb/</guid>
      <description>

&lt;p&gt;Choria includes a &lt;a href=&#34;https://docs.puppet.com/puppetdb/&#34;&gt;PuppetDB&lt;/a&gt; based discovery plugin but it&amp;rsquo;s not enabled by default.&lt;/p&gt;

&lt;p&gt;This is an advanced PuppetDB plugin that is subcollective aware and supports node, fact, class and agent filters. It uses the new &lt;em&gt;Puppet PQL&lt;/em&gt; under the hood and so requires a very recent PuppetDB.&lt;/p&gt;

&lt;p&gt;Using it you get a very fast discovery workflow but without the awareness of which nodes are actually up and responding, it&amp;rsquo;s suitable for situations where you have a stable network, or really care to know when known machines are not responding as is common during software deployments. It makes a very comfortable to use default discovery plugin.&lt;/p&gt;

&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;

&lt;p&gt;Your MCollective &lt;em&gt;client&lt;/em&gt; machine needs to be able to communicate with PuppetDB on its SSL port. The client will use the same certificates that was created using _mco choria request&lt;em&gt;cert&lt;/em&gt; so you don&amp;rsquo;t need to do anything with the normal Puppet client-tools config, though you might find setting those up helpful.&lt;/p&gt;

&lt;div class=&#34;notices warning&#34; &gt;&lt;p&gt;Giving people access to PuppetDB in this manner will allow them to do all kinds of thing with your data as there are no ACL features in PuppetDB, consider carefully who you allow to connect to PuppetDB on any port.&lt;/p&gt;
&lt;/div&gt;


&lt;h2 id=&#34;using&#34;&gt;Using&lt;/h2&gt;

&lt;p&gt;In general you can just go about using MCollective as normal after configuring it (see below).  All your usual filters like &lt;em&gt;-I&lt;/em&gt;, &lt;em&gt;-C&lt;/em&gt;, &lt;em&gt;-W&lt;/em&gt; etc all work as normal.&lt;/p&gt;

&lt;p&gt;Your discovery should take a fraction of a second rather than the usual 2 seconds or more and will reflect what PuppetDB thinks it should be out there.&lt;/p&gt;

&lt;h3 id=&#34;pql&#34;&gt;PQL&lt;/h3&gt;

&lt;p&gt;There is an advanced feature that lets you construct complex queries using the &lt;a href=&#34;https://docs.puppet.com/puppetdb/latest/api/query/v4/pql.html&#34;&gt;PQL language&lt;/a&gt; for discovery though.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mco find -I &amp;quot;pql:nodes[certname] { certname ~ &#39;^dev&#39; }&amp;quot;
dev3.example.net
dev1.example.net
dev2.example.net
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can construct very complex queries that can match even to the level of specific properties of resources and classes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mco find -I &amp;quot;pql:inventory[certname] { resources { type = &#39;User&#39; and title = &#39;rip&#39; and parameters.ensure = &#39;present&#39;}}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PQL queries comes in all forms, there are many examples at the Puppet docs. Though you should note that you must ensure you only ever return the certname as in the above example.&lt;/p&gt;

&lt;p&gt;If you configure the Puppet Client Tools (see below) you can test these queries on the CLI:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;% puppet query &amp;quot;inventory[certname] { resources { type = &#39;User&#39; and title = &#39;rip&#39; and parameters.ensure = &#39;present&#39;}}&amp;quot;
[
  {
    &amp;quot;certname&amp;quot;: &amp;quot;host1.example.net&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your queries &lt;strong&gt;MUST&lt;/strong&gt; return the data as above - just the certname property.&lt;/p&gt;

&lt;h2 id=&#34;configuring-mcollective&#34;&gt;Configuring MCollective&lt;/h2&gt;

&lt;p&gt;You do not have to configure this to be the default discovery method, instead you can use it just when you need or want:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mco puppet status --dm=choria
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By passing &lt;em&gt;&amp;ndash;dm=choria&lt;/em&gt; to MCollective commands you enable this discovery method just for the duration of that command.  This is a good way to test the feature before enabling it by default.&lt;/p&gt;

&lt;p&gt;You can set this discovery method to be your default by adding the following hiera data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective::client_config:
  default_discovery_method: &amp;quot;choria&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default it will attempt to find PuppetDB on puppet:8081, you can configure this &lt;a href=&#34;../../deployment/dns/&#34;&gt;using DNS or manually&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;configuring-puppet-optional&#34;&gt;Configuring Puppet (optional)&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s convenient to be able to query PuppetDB using the &lt;em&gt;puppet query&lt;/em&gt; command especially if you want to use the custom PQL based discovery, create ~/.puppetlabs/client-tools/puppetdb.conf with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;puppetdb&amp;quot;: {
    &amp;quot;server_urls&amp;quot;: &amp;quot;https://puppet:8081&amp;quot;,
    &amp;quot;cacert&amp;quot;: &amp;quot;/home/rip/.puppetlabs/etc/puppet/ssl/certs/ca.pem&amp;quot;,
    &amp;quot;cert&amp;quot;: &amp;quot;/home/rip/.puppetlabs/etc/puppet/ssl/certs/rip.mcollective.pem&amp;quot;,
    &amp;quot;key&amp;quot;: &amp;quot;/home/rip/.puppetlabs/etc/puppet/ssl/private_keys/rip.mcollective.pem&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then install the puppet-client-tools package from the Puppet Labs repos.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MCollective AAA</title>
      <link>http://docs.choria.io/configuration/aaa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/aaa/</guid>
      <description>

&lt;p&gt;MCollective features a full suite of Authentication, Authorization and Auditing capabilities.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Authentication - &lt;em&gt;who&lt;/em&gt; you are, derived from a certificate&lt;/li&gt;
&lt;li&gt;Authorization - &lt;em&gt;what&lt;/em&gt; you may do on any given node, keyed to your certificate based identity&lt;/li&gt;
&lt;li&gt;Auditing - &lt;em&gt;log&lt;/em&gt; of what you did, showing your certificate based identitty and all requests&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Earlier we made a certificate called &lt;em&gt;rip.mcollective&lt;/em&gt; which is used to establish your identity as &lt;em&gt;choria=rip.mcollective&lt;/em&gt; which will be used throughout in the AAA system.&lt;/p&gt;

&lt;h2 id=&#34;authorization&#34;&gt;Authorization&lt;/h2&gt;

&lt;p&gt;Choria sets up the popular &lt;a href=&#34;https://github.com/puppetlabs/mcollective-actionpolicy-auth&#34;&gt;Action Policy&lt;/a&gt; based authorization and does so in a &lt;em&gt;default deny&lt;/em&gt; mode which means by default, no-one can make any requests.&lt;/p&gt;

&lt;p&gt;Some plugins may elect to ship authorization rules that allow certain read only actions by default - like the &lt;em&gt;mco puppet status&lt;/em&gt; command, but you can change or override all of this.&lt;/p&gt;

&lt;h3 id=&#34;site-policies&#34;&gt;Site Policies&lt;/h3&gt;

&lt;p&gt;You can allow your own users only certain access, previously when configuring your first user we did this already via &lt;em&gt;Hiera&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective::site_policies:
  - action: &amp;quot;allow&amp;quot;
    callers: &amp;quot;choria=rip.mcollective&amp;quot;
    actions: &amp;quot;*&amp;quot;
    facts: &amp;quot;*&amp;quot;
    classes: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll note this is an array so you can have many policies, site policies are applied to &lt;strong&gt;all agents&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;agent-specific-policies&#34;&gt;Agent specific policies&lt;/h3&gt;

&lt;p&gt;This will allow a specific certificate to only &lt;em&gt;block&lt;/em&gt; ip addresses on my firewall but nothing else:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_agent_iptables::policies:
  - action: &amp;quot;allow&amp;quot;
    callers: &amp;quot;choria=typhon.mcollective&amp;quot;
    actions: &amp;quot;block&amp;quot;
    facts: &amp;quot;*&amp;quot;
    classes: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For full details see the &lt;a href=&#34;https://github.com/puppetlabs/mcollective-actionpolicy-auth&#34;&gt;Action Policy&lt;/a&gt; docs.&lt;/p&gt;

&lt;h3 id=&#34;per-plugin-default-override&#34;&gt;Per plugin default override&lt;/h3&gt;

&lt;p&gt;As mentioned by default all actions are denied across all agents, you can change a specific agent to default allow via hiera:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_agent_puppet::policy_default: allow
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;site-wide-default-policy&#34;&gt;Site wide default policy&lt;/h3&gt;

&lt;p&gt;By default all actions are denied, if like in a Lab environment you want to simplify things and all all actions across all agents, you can set this in &lt;em&gt;Hiera&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&#34;notices warning&#34; &gt;&lt;p&gt;Enabling this will allow anyone with a signed mcollective cert to perform any action on any node, please consider carefully before changing this setting.&lt;/p&gt;
&lt;/div&gt;


&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective::policy_default: allow
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;authentication&#34;&gt;Authentication&lt;/h2&gt;

&lt;h3 id=&#34;custom-certificate-names&#34;&gt;Custom certificate names&lt;/h3&gt;

&lt;p&gt;Authentication is done via the certname embedded in the certificate, certificates must be signed by the Puppet CA.&lt;/p&gt;

&lt;p&gt;By default the only certificates that will be accepted are those matching the pattern &lt;em&gt;/.mcollective$/&lt;/em&gt;, if you have some special needs you can adjust this via &lt;em&gt;Hiera&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_choria::config:
  security.certname_whitelist: &amp;quot;bob, jill, /\.mcollective$/&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can request custom certificate names on the CLI:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mco choria request_cert --certname bob
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;revoking-access&#34;&gt;Revoking access&lt;/h3&gt;

&lt;p&gt;Public certificates are distributed automatically but will never be removed.  To remove them you have to manually arrange for the files to be deleted from all nodes - perhaps using Puppet - before a new one can be distributed.  These live in &lt;em&gt;/etc/puppetlabs/mcollective/choria_security/public_certs&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&#34;privileged-certificates&#34;&gt;Privileged certificates&lt;/h3&gt;

&lt;p&gt;Unless specifically requested you should never use certificates matching the pattern &lt;em&gt;/.privileged.mcollective$/&lt;/em&gt;, this is an advanced feature that is reserved for a future REST server where Authentication is delegated to a trusted piece of software.&lt;/p&gt;

&lt;h2 id=&#34;auditing&#34;&gt;Auditing&lt;/h2&gt;

&lt;p&gt;Auditing is configured to write to a log file &lt;em&gt;/var/log/puppetlabs/mcollective-audit.log&lt;/em&gt; by default, you should set up rotation if desired (not done by the module), it&amp;rsquo;s contents are like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[2016-12-13 08:32:34 UTC] reqid=30d706be63e555db8c073ec17a23af44: reqtime=1481617954 caller=choria=rip.mcollective@dev3.example.net agent=rpcutil action=ping data={:process_results=&amp;gt;true}
[2016-12-13 08:32:43 UTC] reqid=e0c60ad2f58d52699e6524039decc257: reqtime=1481617963 caller=choria=rip.mcollective@dev3.example.net agent=puppet action=status data={:process_results=&amp;gt;true}
[2016-12-13 13:15:09 UTC] reqid=1235e001c9b15414b748ab26607e1063: reqtime=1481634909 caller=choria=rip.mcollective@dev3.example.net agent=puppet action=status data={:process_results=&amp;gt;true}
[2016-12-13 13:15:35 UTC] reqid=cf95bc7621ff55a8a197e3f2e394406e: reqtime=1481634935 caller=choria=rip.mcollective@dev3.example.net agent=puppet action=status data={:process_results=&amp;gt;true}
[2016-12-13 13:15:43 UTC] reqid=18192c7f260c5788a33b60ce4f01771c: reqtime=1481634943 caller=choria=rip.mcollective@dev3.example.net agent=puppet action=status data={:process_results=&amp;gt;true}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Plugin Distribution</title>
      <link>http://docs.choria.io/configuration/plugins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/plugins/</guid>
      <description>

&lt;p&gt;MCollective have many plugins, the most common ones are &lt;em&gt;agents&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In the past packaging was done via RPM or Deb packages, this was extremely limited requiring extra work to make configuration modules and of course only worked on those operating systems.&lt;/p&gt;

&lt;h2 id=&#34;packaging&#34;&gt;Packaging&lt;/h2&gt;

&lt;p&gt;Choria includes a packager that turns a common MCollective plugin into a Puppet Module like the &lt;a href=&#34;https://forge.puppet.com/ripienaar/mcollective_agent_puppet&#34;&gt;Puppet Agent one&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can package your own modules in this manner:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cd youragent
$ mco plugin package --format aiomodulepackage --vendor yourco
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will produce a Puppet module that you can install using Choria by adding it to the list of plugins to manage:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective::plugin_classes:
  - mcollective_agent_youragent
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;plugin-configuration&#34;&gt;Plugin Configuration&lt;/h2&gt;

&lt;p&gt;Many MCollective plugins have extensive configuration, some times Server and Client side.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;ripienaar-mcollective&lt;/em&gt; module lets you configure any setting in any plugin via &lt;em&gt;Hiera&lt;/em&gt; data, here&amp;rsquo;s an example of configuring the Puppet one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_agent_puppet::config:
  &amp;quot;splay&amp;quot;: false
  &amp;quot;signal_daemon&amp;quot;: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This creates files in &lt;em&gt;/etc/puppetlabs/mcollective/plugin.d&lt;/em&gt; with the per plugin settings.  This will only work on plugins distributed using the method shown above.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gem Distribution</title>
      <link>http://docs.choria.io/configuration/gems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/gems/</guid>
      <description>&lt;p&gt;Many sites have policies prohibiting their nodes from accessing dependencies via the internet.  Choria allows those to manage their own dependencies and disable the built in Gem management:&lt;/p&gt;

&lt;p&gt;You can package the &lt;a href=&#34;https://rubygems.org/gems/nats-pure&#34;&gt;nats-pure&lt;/a&gt; dependency yourself, perhaps using &lt;a href=&#34;https://fpm.readthedocs.io/en/latest/&#34;&gt;fpm&lt;/a&gt;, and distribute it using your own packages.&lt;/p&gt;

&lt;p&gt;You can configure Choria to not install any gem dependencies via &lt;em&gt;Hiera&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_choria::manage_gem_dependencies: false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then configure Choria to install these for you via the system packager, lets say you called the package &lt;em&gt;aio-nats-pure&lt;/em&gt;, again via &lt;em&gt;Hiera&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_choria::package_dependencies:
  &amp;quot;aio-nats-pure&amp;quot;: &amp;quot;0.1.2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will now install this package for you and allow you to manage the version of it, ordering is handled correctly and MCollective will restart appropriately.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Application Orchestrator</title>
      <link>http://docs.choria.io/configuration/app_orchestration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.choria.io/configuration/app_orchestration/</guid>
      <description>

&lt;p&gt;Choria includes an Open Source Orchestrator compatible with the Puppet Site catalog system that allows you to describe a multi node deployment.&lt;/p&gt;

&lt;p&gt;This orchestrator interprets the environment graphs Puppet produces and runs your nodes in the right order.&lt;/p&gt;

&lt;p&gt;It uses the standard Puppet agent, best installed with ripienaar/mcollective_agent_puppet.&lt;/p&gt;

&lt;p&gt;To use it requires some careful configuration, see the bottom of this page for details of that.&lt;/p&gt;

&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;

&lt;p&gt;The Puppet Site catalogs allow you describe a graph of multiple nodes, their dependencies, ordering and exchange information between them.&lt;/p&gt;

&lt;p&gt;Here is a sample site with a Lamp stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-puppet&#34;&gt;site {
  lamp{&#39;app2&#39;:
    db_user       =&amp;gt; &#39;user&#39;,
    db_password   =&amp;gt; &#39;secret&#39;,
    web_instances =&amp;gt; 3,
    nodes         =&amp;gt; {
      Node[&#39;dev1.example.net&#39;] =&amp;gt; Lamp::Mysql[&#39;app2&#39;],
      Node[&#39;dev2.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app2-1&#39;],
      Node[&#39;dev3.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app2-2&#39;],
      Node[&#39;dev4.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app2-3&#39;]
    }
  }

  lamp{&#39;app1&#39;:
    db_user       =&amp;gt; &#39;user&#39;,
    db_password   =&amp;gt; &#39;secret&#39;,
    web_instances =&amp;gt; 3,
    nodes         =&amp;gt; {
      Node[&#39;dev1.example.net&#39;] =&amp;gt; Lamp::Mysql[&#39;app1&#39;],
      Node[&#39;dev2.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app1-1&#39;],
      Node[&#39;dev3.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app1-2&#39;],
      Node[&#39;dev4.example.net&#39;] =&amp;gt; Lamp::Webapp[&#39;app1-3&#39;]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can infer from this that there are node groups and that the &lt;em&gt;Lamp::Mysql&lt;/em&gt; needs to be done prior to any &lt;em&gt;Lamp::Webapp&lt;/em&gt;.  The orchastration part of this involves running Puppet in the desired order.&lt;/p&gt;

&lt;p&gt;This tool will ask Puppet for the catalog, and after analysing it for cyclic dependencies, view or deploy it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mco choria run
Puppet Site Plan for the production Environment

2 applications on 4 managed nodes:

        Lamp[app1]
        Lamp[app2]

Node groups and run order:
   ------------------------------------------------------------------
        dev1.example.net
                Lamp[app1] -&amp;gt; Lamp::Mysql[app1]
                Lamp[app2] -&amp;gt; Lamp::Mysql[app2]

   ------------------------------------------------------------------
        dev2.example.net
                Lamp[app1] -&amp;gt; Lamp::Webapp[app1-1]
                Lamp[app2] -&amp;gt; Lamp::Webapp[app2-1]

        dev3.example.net
                Lamp[app1] -&amp;gt; Lamp::Webapp[app1-2]
                Lamp[app2] -&amp;gt; Lamp::Webapp[app2-2]

        dev4.example.net
                Lamp[app1] -&amp;gt; Lamp::Webapp[app1-3]
                Lamp[app2] -&amp;gt; Lamp::Webapp[app2-3]

Are you sure you wish to run this plan? (y/n) y

        2016-07-14 13:28:38 +0200: Checking if 4 nodes are enabled
        2016-07-14 13:28:38 +0200: Disabling Puppet on 4 nodes: Disabled during orchastration job initiated by rip.mcollective at 2016-07-14 13:28:38 +0200

Running node group 1 with 1 nodes batched 4 a time
        2016-07-14 13:28:38 +0200: Waiting for 1 nodes to become idle
        2016-07-14 13:28:38 +0200: Enabling Puppet on 1 nodes
        2016-07-14 13:28:38 +0200: Running Puppet on 1 nodes
        2016-07-14 13:28:38 +0200: Waiting for 1 nodes to start a run
        2016-07-14 13:28:43 +0200: Waiting for 1 nodes to become idle
        2016-07-14 13:29:03 +0200: Waiting for 1 nodes to become idle
        2016-07-14 13:29:24 +0200: Waiting for 1 nodes to become idle

Succesful run of 1 nodes in group 1 in 61.46 seconds

Running node group 2 with 3 nodes batched 4 a time
        2016-07-14 13:29:39 +0200: Waiting for 3 nodes to become idle
        2016-07-14 13:29:39 +0200: Enabling Puppet on 3 nodes
        2016-07-14 13:29:39 +0200: Running Puppet on 3 nodes
        2016-07-14 13:29:39 +0200: Waiting for 3 nodes to start a run
        2016-07-14 13:29:45 +0200: Waiting for 3 nodes to become idle
        2016-07-14 13:30:05 +0200: Waiting for 3 nodes to become idle
        2016-07-14 13:30:26 +0200: Waiting for 3 nodes to become idle

Succesful run of 3 nodes in group 2 in 61.78 seconds

        2016-07-14 13:30:41 +0200: Enabling Puppet on 4 nodes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Setting up involves a few things, the instructions below work with the FOSS stack&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;You should already have security certificates setup for Choria, run _mco choria request&lt;em&gt;cert&lt;/em&gt; if not.&lt;/li&gt;
&lt;li&gt;Your Puppet Server is found by looking in DNS or manual config as per the deployment guide, defaults to &lt;em&gt;puppet:8140&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On your PuppetServer use the _puppetlabs/puppet&lt;em&gt;authorization&lt;/em&gt; module to add a authorization rule:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-puppet&#34;&gt;puppet_authorization::rule { &amp;quot;puppetlabs environment&amp;quot;:
  match_request_path   =&amp;gt; &amp;quot;/puppet/v3/environment&amp;quot;,
  match_request_type   =&amp;gt; &amp;quot;path&amp;quot;,
  match_request_method =&amp;gt; &amp;quot;get&amp;quot;,
  allow                =&amp;gt; [&amp;quot;*.mcollective&amp;quot;],
  sort_order           =&amp;gt; 510,
  path                 =&amp;gt; &amp;quot;/etc/puppetlabs/puppetserver/conf.d/auth.conf&amp;quot;,
  notify               =&amp;gt; Class[&amp;quot;puppetserver::config&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives certificates *.mcollective access to the environment graph, adjust to local taste.&lt;/p&gt;

&lt;p&gt;Add in the old /etc/puppetlabs/puppet/auth.conf add an entry:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;path /puppet/v3/environment
method find
allow *
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In your &lt;em&gt;/etc/puppetlabs/puppet/puppet.conf&lt;/em&gt; add:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[master]
app_management = true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally you need to have authorization to use the actions needed on the Puppet Agent, you can give yourself these by adding the following data to Hiera if you do not already have AAA rules, in this manner you can allow app runs to just certain environments, machines or whichever nodes you like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;mcollective_agent_puppet::policies:
  - action: &amp;quot;allow&amp;quot;
    callers: &amp;quot;puppet=rip.mcollective&amp;quot;
    actions: &amp;quot;disable,enable,last_run_summary,runonce,status&amp;quot;
    facts: &amp;quot;*&amp;quot;
    classes: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;logic-flow&#34;&gt;Logic Flow&lt;/h2&gt;

&lt;p&gt;To give you an idea for what these deployments actually do, this is the logic flow they take:&lt;/p&gt;

&lt;p&gt;Once it has the site catalog from the Puppet Server it finds the list of all nodes in the site and also groups of them and the order to run in.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Checks if all the nodes are enabled, if any are disabled it cannot continue&lt;/li&gt;
&lt;li&gt;Disables all the nodes so no automated or human triggered runs can interfere&lt;/li&gt;
&lt;li&gt;Waits for all nodes to become idle, if after a long timeout they don&amp;rsquo;t exit&lt;/li&gt;
&lt;li&gt;Iterate the groups finding the nodes per group, loop them possibly in small batches

&lt;ol&gt;
&lt;li&gt;Enable Puppet on these nodes&lt;/li&gt;
&lt;li&gt;Run Puppet&lt;/li&gt;
&lt;li&gt;Wait for it to start, exit if they do not idle after a long time&lt;/li&gt;
&lt;li&gt;Wait for it to become idle, exit if they do not go idle after a long time&lt;/li&gt;
&lt;li&gt;Disable them all&lt;/li&gt;
&lt;li&gt;If any of the nodes had failed resources, fail&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Enable all the nodes on success, Disable all the nodes on fail since the stack is now inconsistent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There is some improvements to be made, specifically there&amp;rsquo;s a small window between
running the nodes and disabling them again that another run can start, end of the
day though it works out, all the daemons are idle when the status is fetched and
this is definitely for a run started after the one we needed.  So the end out come
is the same&lt;/p&gt;

&lt;p&gt;##Â Status&lt;/p&gt;

&lt;p&gt;The basic feature work and it works with the Open Source PuppetServer too, but the feature in Puppet is extremely new and needs some improvement, this tool is going to be only as good as what Puppet provides.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>